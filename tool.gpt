export: connect-broker, create-topic, delete-topic, list-topics, send-data-topic, send-file-topic, recv-topic-data, recv-topic-file, pipe-source, pipe-sink, pipe-filter
description: A toolset for talking to kafka broker cluster.

---
name: create-topic
description: create a kafka topic
args: name: topic name
args: partitions: (optional) number of partitions
args: replicas: (optional) number of replicas

#!/usr/bin/env bash

${GPTSCRIPT_TOOL_DIR}/bin/kaf topic create ${name} --partitions ${partitions:-1} --replicas ${replicas:-1} || true


---
name: delete-topic
description: delete a kafka topic
args: name: topic name

#!/usr/bin/env bash
${GPTSCRIPT_TOOL_DIR}/bin/kaf topic delete ${name} || true

---
name: list-topics
description: list all topics in broker cluster

#!/usr/bin/env bash

${GPTSCRIPT_TOOL_DIR}/bin/kaf topics

---
name: send-data-topic
description: send or produce input data to a topic
args: name: topic name
args: input: data to send

#!/usr/bin/env bash

echo ${input} | ${GPTSCRIPT_TOOL_DIR}/bin/kaf produce ${name} > /tmp/send_dump1 2> /tmp/send_dump2

---
name: send-file-topic
description: send or produce file content to a topic
args: name: topic name
args: file: name of file to send

#!/usr/bin/env bash

${GPTSCRIPT_TOOL_DIR}/bin/kaf produce ${name} < ${file} > /tmp/send_dump1 2> /tmp/send_dump2

---
name: recv-topic-data
description: receive or consume data from a topic
args: name: topic name
args: offset: offset to start consuming, oldest, newest, or int
args: tail: last n message to consume per partition
args: output: output format, default, raw, or json

#!/usr/bin/env bash

output=${output:-raw}
if [[ -n ${tail} ]]; then
  ${GPTSCRIPT_TOOL_DIR}/bin/kaf consume ${name} --output ${output} -n ${tail}
else
  offset=${offset:-oldest}
  ${GPTSCRIPT_TOOL_DIR}/bin/kaf consume ${name} --output ${output} --offset ${offset}
fi


---
name: recv-topic-file
description: receive or consume data from a topic into a file
args: name: topic name
args: file: name of file to put data in
args: offset: offset to start consuming, oldest, newest, or int
args: tail: last n message to consume per partition
args: output: output format, default, raw, or json

#!/usr/bin/env bash

output=${output:-raw}
if [[ -n ${tail} ]]; then
  ${GPTSCRIPT_TOOL_DIR}/bin/kaf consume ${name} --output ${output} -n ${tail} > ${file}
else
  offset=${offset:-oldest}
  ${GPTSCRIPT_TOOL_DIR}/bin/kaf consume ${name} --output ${output} --offset ${offset} > ${file}
fi

---
name: connect-broker
description: connect to kafka brokers. Install kaf first
args: cluster: kafka cluster name
args: brokers: comma separated list of brokers ip:port
tools: sys.exec, sys.http.get, sys.write

#!/usr/bin/env bash

if [[ ! -d ${GPTSCRIPT_TOOL_DIR}/bin ]]; then
   mkdir ${GPTSCRIPT_TOOL_DIR}/bin
fi
if [[ ! -f ${GPTSCRIPT_TOOL_DIR}/bin/kaf ]]; then
   echo "install kafka client kaf"
   curl https://raw.githubusercontent.com/birdayz/kaf/master/godownloader.sh | BINDIR=${GPTSCRIPT_TOOL_DIR}/bin bash
   export PATH=$PATH:${GPTSCRIPT_TOOL_DIR}/bin
fi
if ${GPTSCRIPT_TOOL_DIR}/bin/kaf config add-cluster ${cluster} --brokers ${brokers}; then
  ${GPTSCRIPT_TOOL_DIR}/bin/kaf config use-cluster ${cluster}
fi

---
name: pipe-source
description: execute a command and send its output to topic, as the source of pipe.
args: cmd: the command to run including its all arguments
args: topic: the topic to send the output of command
tools: sys.exec

#!/usr/bin/env bash

${cmd} | ${GPTSCRIPT_TOOL_DIR}/bin/kaf produce ${topic}


---
name: pipe-sink
description: execute a command and read its input from topic, as the final destination or sink of pipe, it ends the pipe.
args: cmd: the command to run including its all arguments
args: topic: the topic to read receive as input of command
tools: sys.exec

#!/usr/bin/env bash

sleep 3 #wait for pipe source
${GPTSCRIPT_TOOL_DIR}/bin/kaf consume ${topic} --output raw | ${cmd}
${GPTSCRIPT_TOOL_DIR}/bin/kaf topic delete ${topic} # cleanup

---
name: pipe-filter
description: execute a command and read its input from intopic and write its output to outtopic, as a filter in pipe
args: cmd: the command to run including its all arguments
args: intopic: the topic to read receive as input of command
args: outtopic: the topic to send the output of command

#!/usr/bin/env bash

sleep 3 # wait for pipe source
${GPTSCRIPT_TOOL_DIR}/bin/kaf consume ${intopic} --output raw | ${cmd} | ${GPTSCRIPT_TOOL_DIR}/bin/kaf produce ${outtopic}
${GPTSCRIPT_TOOL_DIR}/bin/kaf topic delete ${intopic} # clean up

